{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import msal\n",
    "from msal.application import ConfidentialClientApplication\n",
    "from dotenv import load_dotenv\n",
    "import jwt\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r'C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search'\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")\n",
    "\n",
    "#load logging \n",
    "from utils.ml_logging import get_logger\n",
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure_search_documents==11.4.0b11 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (11.4.0b11)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from azure_search_documents==11.4.0b11) (1.29.5)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from azure_search_documents==11.4.0b11) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from azure_search_documents==11.4.0b11) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure_search_documents==11.4.0b11) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure_search_documents==11.4.0b11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryLanguage,\n",
    "    QueryType,\n",
    "    RawVectorQuery,\n",
    "    VectorizableTextQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    AzureOpenAIEmbeddingSkill,  \n",
    "    AzureOpenAIParameters,  \n",
    "    AzureOpenAIVectorizer,  \n",
    "    ExhaustiveKnnParameters,  \n",
    "    ExhaustiveKnnVectorSearchAlgorithmConfiguration,\n",
    "    FieldMapping,  \n",
    "    HnswParameters,  \n",
    "    HnswVectorSearchAlgorithmConfiguration,  \n",
    "    InputFieldMappingEntry,  \n",
    "    OutputFieldMappingEntry,  \n",
    "    PrioritizedFields,    \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SearchIndex,  \n",
    "    SearchIndexer,  \n",
    "    SearchIndexerDataContainer,  \n",
    "    SearchIndexerDataSourceConnection,  \n",
    "    SearchIndexerSkillset,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticField,  \n",
    "    SemanticSettings,  \n",
    "    SplitSkill,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmKind,  \n",
    "    VectorSearchProfile,  \n",
    ")  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "import os  \n",
    "  \n",
    "# Configure environment variables  \n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "key = os.getenv(\"SEARCH_KEY\")  \n",
    "model: str = \"text-embedding-ada-002\"  \n",
    "# blob_connection_string = os.getenv(\"BLOB_CONNECTION_STRING\")  \n",
    "# container_name = os.getenv(\"BLOB_CONTAINER_NAME\")  \n",
    "credential = AzureKeyCredential(key)  \n",
    "search_client = SearchClient(endpoint=service_endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-index created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile=\"myHnswProfile\"),\n",
    "    SearchField(name=\"group_ids\", type=SearchFieldDataType.Collection(SearchFieldDataType.String), filterable=True)\n",
    "      \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswVectorSearchAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            kind=VectorSearchAlgorithmKind.HNSW,  \n",
    "            parameters=HnswParameters(  \n",
    "                m=4,  \n",
    "                ef_construction=400,  \n",
    "                ef_search=500,  \n",
    "                metric=\"cosine\",  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnVectorSearchAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=\"cosine\",  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm=\"myExhaustiveKnn\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "                deployment_id=model,  \n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=PrioritizedFields(  \n",
    "        prioritized_content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Create the semantic settings with the configuration  \n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index with the semantic settings  \n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_settings=semantic_settings)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-index-skillset created\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "  \n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=2048,  \n",
    "    page_overlap_length=20,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "    deployment_id=model,  \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill]\n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source \n",
    "ds_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))\n",
    "container = SearchIndexerDataContainer(name=container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} created')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharepoint-indexing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
